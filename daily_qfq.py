#!/usr/bin/env python3
"""
å‰å¤æƒæ—¥çº¿æ•°æ®åŒæ­¥ï¼ˆå†™å…¥ new è¡¨ï¼Œä¸åˆ é™¤æ—§è¡¨ï¼‰
"""

import os
import sys
import time
import tushare as ts
import pandas as pd
from datetime import datetime, timedelta
from concurrent.futures import ThreadPoolExecutor, as_completed
from sqlalchemy import inspect, text
import warnings
from tqdm import tqdm

# æ·»åŠ å½“å‰ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from db_handler import get_db_handler

warnings.filterwarnings("ignore", category=FutureWarning, module=r"tushare\.pro\.data_pro")


TARGET_TABLE = "daily_qfq_new"   # ************ â¬…â¬…â¬… ç°åœ¨å†™å…¥ NEW è¡¨ ************


def get_latest_trade_date(pro):
    try:
        now = datetime.now()
        today = now.strftime('%Y%m%d')
        morning_9am = now.replace(hour=16, minute=0, second=0, microsecond=0)
        start_date = (now - timedelta(days=30)).strftime('%Y%m%d')

        trade_cal = pro.trade_cal(exchange='', start_date=start_date, end_date=today)
        trade_cal = trade_cal[trade_cal['is_open'] == 1]

        if trade_cal.empty:
            return today

        return trade_cal.iloc[1]['cal_date'] if now < morning_9am else trade_cal.iloc[0]['cal_date']
    except:
        return datetime.now().strftime('%Y%m%d')


def get_stock_codes(db_handler):
    try:
        query = "SELECT ts_code FROM stock_basic"
        result = pd.read_sql(query, con=db_handler.get_engine())
        return result['ts_code'].tolist()
    except:
        return []


def get_qfq_data(ts_code, start_date, max_retries=3):
    for attempt in range(max_retries):
        try:
            df = ts.pro_bar(ts_code=ts_code, adj='qfq', start_date=start_date)
            if df is None:
                return pd.DataFrame()
            if not df.empty:
                df['ts_code'] = ts_code
            return df
        except:
            time.sleep((attempt + 1) * 2)
    return pd.DataFrame()


def need_sync_daily_qfq(db_handler, pro):
    """ä¿ç•™åŸé€»è¾‘ï¼Œä½†æ£€æŸ¥ old è¡¨ daily_qfq"""
    try:
        latest_trade_date = get_latest_trade_date(pro)
        total_stocks = len(get_stock_codes(db_handler))

        query = f"SELECT COUNT(DISTINCT ts_code) as count FROM daily_qfq WHERE trade_date = '{latest_trade_date}'"
        result = pd.read_sql(query, con=db_handler.get_engine())
        latest_count = result.iloc[0]['count']
        ratio = latest_count / total_stocks if total_stocks else 0

        if ratio >= 0.9:
            print(f"æ•°æ®å®Œæ•´ {latest_count}/{total_stocks} ({ratio:.1%})")
            return False
        else:
            print(f"æ•°æ®ä¸å®Œæ•´ {latest_count}/{total_stocks} ({ratio:.1%})ï¼Œéœ€è¦åŒæ­¥")
            return True
    except:
        return True


def sync_daily_qfq(max_workers=16):
    print("=" * 50)
    print("åŒæ­¥å‰å¤æƒæ—¥çº¿æ•°æ® â†’ å†™å…¥ new è¡¨ï¼Œä¸åˆ é™¤æ—§è¡¨")
    print("=" * 50)

    try:
        db_handler = get_db_handler()

        token = os.getenv('TUSHARE_TOKEN')
        if not token:
            print("é”™è¯¯: è¯·è®¾ç½® TUSHARE_TOKEN")
            return False

        ts.set_token(token)
        pro = ts.pro_api()

        stock_codes = get_stock_codes(db_handler)
        if not stock_codes:
            print("æ— è‚¡ç¥¨ä»£ç ")
            return False

        print(f"å…± {len(stock_codes)} åªè‚¡ç¥¨")

        end_date = get_latest_trade_date(pro)
        print(f"åŒæ­¥åˆ°: {end_date}")

        if not need_sync_daily_qfq(db_handler, pro):
            print("æ•°æ®å·²æœ€æ–°ï¼Œä¸åŒæ­¥")
            return True

        # ************ ğŸš« ä¸åˆ é™¤ old è¡¨ daily_qfq ************
        # ************ âœ” åˆ›å»º/è¦†ç›– NEW è¡¨ daily_qfq_new ************
        print(f"å‡†å¤‡å†™å…¥æ–°è¡¨: {TARGET_TABLE}")

        # ç¡®ä¿ new è¡¨æ˜¯å¹²å‡€çš„
        with db_handler.get_engine().connect() as conn:
            print(f"æ¸…ç©ºæˆ–åˆ›å»º {TARGET_TABLE} è¡¨...")
            conn.execute(text(f"DROP TABLE IF EXISTS {TARGET_TABLE}"))
            conn.commit()

        # æ¸…ç†ç¼“å­˜
        with db_handler._table_lock:
            if TARGET_TABLE in db_handler._existing_tables:
                db_handler._existing_tables.remove(TARGET_TABLE)

        total_records = 0
        success_count = 0

        with ThreadPoolExecutor(max_workers=max_workers) as executor:
            future_to_stock = {
                executor.submit(get_qfq_data, ts_code, '20190101'): ts_code
                for ts_code in stock_codes
            }

            print(f"å·²æäº¤ {len(future_to_stock)} ä¸ªä»»åŠ¡")

            first_batch = True
            processed = 0
            failed_codes = []

            with tqdm(total=len(future_to_stock), desc="åŒæ­¥è¿›åº¦", unit="stock") as pbar:
                for future in as_completed(future_to_stock):
                    ts_code = future_to_stock[future]
                    try:
                        df = future.result()
                        if not df.empty:
                            if first_batch:
                                df.to_sql(TARGET_TABLE, db_handler.get_engine(),
                                          if_exists='replace', index=False)

                                db_handler._create_indexes(TARGET_TABLE, df.columns.tolist())
                                first_batch = False
                            else:
                                df.to_sql(TARGET_TABLE, db_handler.get_engine(),
                                          if_exists='append', index=False)

                            total_records += len(df)
                            success_count += 1
                        else:
                            failed_codes.append(f"{ts_code}:æ— æ•°æ®")

                    except Exception as e:
                        failed_codes.append(f"{ts_code}:{e}")

                    processed += 1
                    pbar.update(1)
                    pbar.set_postfix({"æˆåŠŸæ•°": success_count, "å·²å¤„ç†": processed})

        fail_count = len(failed_codes)
        print("åŒæ­¥å®Œæˆ:")
        print(f"  æˆåŠŸ: {success_count}")
        print(f"  å¤±è´¥/æ— æ•°æ®: {fail_count}")
        print(f"  æ€»è®°å½•: {total_records}")
        if failed_codes:
            preview = failed_codes[:10]
            print("  å¤±è´¥æ ·æœ¬:")
            for item in preview:
                print(f"    {item}")
            if fail_count > len(preview):
                print(f"    ... å…¶ä½™ {fail_count - len(preview)} æ¡")

        return True

    except Exception as e:
        print(f"åŒæ­¥å¤±è´¥: {e}")
        return False


def sync_single_stock(ts_code):
    print("=" * 50)
    print(f"åŒæ­¥å•ä¸ªè‚¡ç¥¨ â†’ å†™å…¥ {TARGET_TABLE}")
    print("=" * 50)

    try:
        db_handler = get_db_handler()
        token = os.getenv('TUSHARE_TOKEN')
        if not token:
            print("è¯·è®¾ç½® TUSHARE_TOKEN")
            return False

        ts.set_token(token)

        max_date = db_handler.get_max_date(TARGET_TABLE)
        start_date = (pd.to_datetime(str(max_date)) + timedelta(days=1)).strftime('%Y%m%d') if max_date else '20190101'

        print(f"ä» {start_date} å¼€å§‹åŒæ­¥")

        df = get_qfq_data(ts_code, start_date)
        if df.empty:
            print("æ— æ–°æ•°æ®")
            return True

        ok = db_handler.insert_data(TARGET_TABLE, df, ts_code)
        print(f"{ts_code} åŒæ­¥ {'æˆåŠŸ' if ok else 'å¤±è´¥'}")
        return ok

    except Exception as e:
        print(f"é”™è¯¯: {e}")
        return False


if __name__ == "__main__":
    try:
        if len(sys.argv) == 2 and sys.argv[1].startswith(
                ('000', '001', '002', '300', '600', '601', '603', '605', '688', '689')):
            success = sync_single_stock(sys.argv[1])
        elif len(sys.argv) == 3 and sys.argv[1] == "workers":
            success = sync_daily_qfq(int(sys.argv[2]))
        else:
            success = sync_daily_qfq()

        sys.exit(0 if success else 1)
    except KeyboardInterrupt:
        print("\nç”¨æˆ·ä¸­æ–­")
        sys.exit(0)
